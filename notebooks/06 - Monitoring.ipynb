{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54c2c9f",
   "metadata": {},
   "source": [
    "# Excercise 6: Monitoring of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f9eb65",
   "metadata": {},
   "source": [
    "## 1. Serve Model using Seldon Core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc2036a",
   "metadata": {},
   "source": [
    "### Create Dummy Seldon Core deployment\n",
    "\n",
    "Create a new file in the folder `pipelines` named `seldon-model.yml`:\n",
    "\n",
    "```yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: <yourname>-model\n",
    "spec:\n",
    "  name: <yourname>-model-deployment\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - name: classifier\n",
    "          image: fluescher/seldon-dummy-service\n",
    "    graph:\n",
    "      children: []\n",
    "      endpoint:\n",
    "        type: REST\n",
    "      name: classifier\n",
    "      type: MODEL\n",
    "    name: eligibility\n",
    "    labels:\n",
    "      version: v1\n",
    "    replicas: 1\n",
    "```\n",
    "\n",
    "Replace `<yourname>` with your name.\n",
    "\n",
    "Then run 'kubectl apply -f pipeline' again to update K8s.\n",
    "\n",
    "This will create a new seldon deployment that is exposed over the Api Gateway. Check the deployment state of your model:\n",
    "\n",
    "`kubectl get pods`\n",
    "\n",
    "If you see your deployment running you can continue testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8b025",
   "metadata": {},
   "source": [
    "### Test deployment\n",
    "\n",
    "Our dummy deployment can now be accessed using the api gateway. Execute the following line after replacing `<yourname>` with your name.\n",
    "\n",
    "You should see something like `{\"data\":{\"names\":[],\"ndarray\":[1]},\"meta\":{\"requestPath\":{\"classifier\":\"....\"}}}`\n",
    "which is the result of your modelwhich is the result of your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc8e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-10 12:26:22--  http://mlproduction.dsiag.ch/seldon/olivier/olivier-model/api/v1.0/predictions\n",
      "Resolving mlproduction.dsiag.ch (mlproduction.dsiag.ch)... 35.222.245.65\n",
      "Connecting to mlproduction.dsiag.ch (mlproduction.dsiag.ch)|35.222.245.65|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 215 [application/json]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                     0%[                    ]       0  --.-KB/s               {\"data\":{\"names\":[],\"ndarray\":[1]},\"meta\":{\"metrics\":[{\"key\":\"eligible\",\"type\":\"COUNTER\",\"value\":1},{\"key\":\"not_eligible\",\"type\":\"COUNTER\",\"value\":0}],\"requestPath\":{\"classifier\":\"fluescher/seldon-dummy-service\"}}}\n",
      "-                   100%[===================>]     215  --.-KB/s    in 0s      \n",
      "\n",
      "2022-06-10 12:26:23 (22.8 MB/s) - written to stdout [215/215]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget -O- mlproduction.dsiag.ch/seldon/<yourname>/<yourname>-model/api/v1.0/predictions --post-data '{\"data\": { \"ndarray\": [[25000, 189625]]}}' --header='Content-Type:application/json'\n",
    "!wget -O- mlproduction.dsiag.ch/seldon/olivier/olivier-model/api/v1.0/predictions --post-data '{\"data\": { \"ndarray\": [[25000, 189625]]}}' --header='Content-Type:application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c3d44",
   "metadata": {},
   "source": [
    "### Check default metrics\n",
    "\n",
    "Right after deployment, a selection of basic metrics is already collected by Seldon. \n",
    "\n",
    "Open Grafana: http://monitoring.mlproduction.dsiag.ch\n",
    "\n",
    "User: admin\n",
    "Password: password\n",
    "\n",
    "To create load (simulate a click on the webpage), you can execute the following line, after replacing `<yourname>`, and let it run while checking in Grafana... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !NAMESPACE=<yourname> MODEL=<yourname>-model ../services/create-load.sh\n",
    "!NAMESPACE=olivier MODEL=olivier-model ../services/create-load.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7d0d8",
   "metadata": {},
   "source": [
    "Questions: \n",
    "- Which metrics are collected? \n",
    "- Are there metrics that are visible in the dashboard but do not update?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d2d0f9",
   "metadata": {},
   "source": [
    "### Query Metrics\n",
    "\n",
    "You can query metrics by clicking on _Explore_ in the Grafana menu. \n",
    "\n",
    "To query metrics you can enter a Prometheus query in the search bar.\n",
    "\n",
    "Have a look at what you can do: https://prometheus.io/docs/prometheus/latest/querying/basics/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a3af7e",
   "metadata": {},
   "source": [
    "### Bonus: Reconfigure Kubernetes deployment\n",
    "\n",
    "If you want that your Sustaino frontend uses the newly deployed service, you need to change `pipeline/frontend.yml`\n",
    "\n",
    "Change\n",
    "\n",
    "```yaml\n",
    "env:\n",
    "    - name: ELIGIBILITY_API_ENDPOINT\n",
    "      value: http://eligibility-service:8100/predict\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```yaml\n",
    "env:\n",
    "    - name: ELIGIBILITY_API_ENDPOINT\n",
    "      value: http://mlproduction.dsiag.ch/seldon/<yourname>/<yourname>-model/api/v1.0/predictions\n",
    "```\n",
    "\n",
    "\n",
    "Remember to replace `<yourname>`\n",
    "\n",
    "Apply the configuration using `kubectl apply -f pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de282059",
   "metadata": {},
   "source": [
    "## Custom Metrics\n",
    "\n",
    "You find the deployed model definition in the folder `services/seldon-dummy`.\n",
    "\n",
    "You can see that it defines two custom metrics. Are you able to find them in Grafana?\n",
    "\n",
    "You can query multiple metrics using the Grafana Query: `{ __name__=~\"metric1|metric2\" }`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91157a0c",
   "metadata": {},
   "source": [
    "### Update your real eligibility model\n",
    "\n",
    "Update your eligibility model to behave like the seldon-dummy service:\n",
    "\n",
    "1. Return custom metrics\n",
    "2. Rebuild it using Cloud Build\n",
    "3. Update your  `seldon-model.yml` to use your image instead of the dummy image\n",
    "4. Reapply your `seldon-model.yml`. Verify that the model does not alway return **1**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
